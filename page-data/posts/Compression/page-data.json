{"componentChunkName":"component---src-templates-category-template-js","path":"/posts/Compression","result":{"pageContext":{"currentCategory":"Compression","categories":["All","PaperReview","Multi-Modal","Compression","Basic","Book","MISC","Project"],"edges":[{"node":{"id":"6414aa7d-92be-54f4-9e97-547ca074f1be","excerpt":"Information Theory (정보이론)  정보이론의 용어 Information : 정보이론에서는 bit로 측정되며 주어진 이벤트에서 발생하는 “surprise”의 양으로 이해할 수 있다. (defined as the amount of “surprise” arising from a given event) 정보원(Source) : 정보가 발생하는 곳 code : 수신자가 받을 수 있는 모든 벡터를 의미 codeword : 부호어, 코드 중에서 generator를 통해 인코딩된 벡터만을 의미 incoding : 보내고자하는 원래 msg(message) symbols에 식별자(parity check symbol)을 더하는 과정 symbol : k개의 bit를 하나로 모아놓은 단위 bit per second (bps):전송되는 bit의 초당 속도 Entropy : Information의 기대값, 특정한 stochastic process에서 생성된 information의 평균 chan…","fields":{"slug":"/InformationTheory/"},"frontmatter":{"categories":"Compression Basic","title":"Information Theory","date":"March 10, 2022"}},"next":{"fields":{"slug":"/INR_ImageCompression/"}},"previous":{"fields":{"slug":"/LiMBeR/"}}},{"node":{"id":"7f243d49-4f08-5202-b573-6c2eec6cb2b8","excerpt":"Implicit Neural Representations for Image Compression Introduction preserves all the information (lossless compression) sacrifices some information for even smaller file sizes (lossy compression) 정보를 모두 보존하는 방향으로의 compression 또는 조금의 정보는 손실이 있어도 파일 크기를 더 줄이는 방향으로의 compression이 존재한다. —> fundamental theoretical limit (Shannon’s entropy) 정보 손실없는 compression이 더 desirable하지만 기본 이론적 한계가 존재한다. 샤넌의 엔트로피는 정보를 표현하는데 필요한 최소 평균 자원량을 말하는데, 샤넌은 아무리 좋은 코드를 설계하더라도 평균 길이가 엔트로피 H(X)보다 짧아질 수 없음을 밝혔다.  Therefore, l…","fields":{"slug":"/INR_ImageCompression/"},"frontmatter":{"categories":"PaperReview Compression","title":"Implicit Neural Representations for Image Compression","date":"March 09, 2022"}},"next":{"fields":{"slug":"/BR_knowabout/"}},"previous":{"fields":{"slug":"/InformationTheory/"}}}]}},"staticQueryHashes":["1073350324","1956554647","2938748437"]}